{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fad097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1fb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003311aa",
   "metadata": {},
   "source": [
    "# 1. Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"유형\": [,\"kykim/electra-kor-base\"],\n",
    "    \"극성\": [,\"klue/roberta-large\"],\n",
    "    \"시제\": [,\"klue/roberta-large\"],\n",
    "    \"확신성\": [,\"kykim/electra-kor-base\"],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffaa476",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b02918",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/test.csv data/result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95b44a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1f9e5d8c299c88b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ubuntu/.cache/huggingface/datasets/csv/default-1f9e5d8c299c88b8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0794bed439184e68b420244d22921e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75d5bd55f5e4105821792d16047fe2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155d4a68422a49598678a67ab508f3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predict split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py38/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:714: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/csv/default-1f9e5d8c299c88b8/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20c3516500947c4a7109ea6059491a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "tds = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\"predict\": \"data/result.csv\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "054d0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, tokenizer, category):\n",
    "    pipe = pipeline(\"text-classification\", model=model, tokenizer = tokenizer, device=0)\n",
    "    result = []\n",
    "    for out in tqdm(pipe(KeyDataset(tds[\"predict\"], \"문장\"), batch_size=128)):\n",
    "        result.append(out[\"label\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a310ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, (pretrained_model_name_or_path, plm) in path.items():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(plm)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path)\n",
    "    result = inference(model, tokenizer, category)\n",
    "    tds[\"predict\"] = tds[\"predict\"].add_column(name=category, column=result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
